{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,LSTM,GRU,Embedding,Bidirectional,RepeatVector,Concatenate,Activation,Dot,Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make sure that we do softmax over time axis = 1\n",
    "#expected shape N X T X D\n",
    "# N=no. of samples\n",
    "#T=sequence length\n",
    "#D vector dimensionality\n",
    "def softmax_over_time(x):\n",
    "    assert(k.ndim(x)>2)\n",
    "    e=k.exp(x-k.max(x,axis=1,keepdims=True))\n",
    "    s=k.sum(e,axis=1,keepdims=True)\n",
    "    return e/s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "EPOCHS=1\n",
    "LATENT_DIM=256\n",
    "LATENT_DIM_DECODER=256\n",
    "NUM_SAMPLES=10000\n",
    "MAX_SEQUENCE_LENGTH=100\n",
    "MAX_NUM_WORDS=20000\n",
    "EMBEDDING_DIM=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts=[]\n",
    "target_texts=[]\n",
    "target_input_texts=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=open(r'F:\\mukulml\\NLP\\spa-eng\\spa.txt',encoding='utf-8',errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.\\tVe.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986655 (cueyayotl)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lines in text[:NUM_SAMPLES]:\n",
    "    eng,spa=lines.split('\\t')[:2]\n",
    "    target_text=spa+' <eos>'\n",
    "    target_input_text='<sos> ' + spa\n",
    "    input_texts.append(eng)\n",
    "    target_texts.append(target_text)\n",
    "    target_input_texts.append(target_input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.', 'Go.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ve. <eos>', 'Vete. <eos>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> Ve.', '<sos> Vete.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_input_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing inputs\n",
    "tokenizer=Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences=tokenizer.texts_to_sequences(input_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15], [15], [15], [15], [302], [167], [167], [167], [167], [167]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word 2 index\n",
    "word2idx_inputs=tokenizer.word_index\n",
    "max_len_input=max(len(s) for s in input_sequences)\n",
    "max_len_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the output \n",
    "tokenizer_o=Tokenizer(num_words=MAX_NUM_WORDS,filters='')\n",
    "tokenizer_o.fit_on_texts(target_texts+target_input_texts)\n",
    "target_sequences=tokenizer_o.texts_to_sequences(target_texts)\n",
    "target_input_sequences=tokenizer_o.texts_to_sequences(target_input_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1468, 1], [1004, 1]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sequences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1468], [2, 1004]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_input_sequences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_output=tokenizer_o.word_index\n",
    "max_len_output=max(len(s) for s in target_sequences)\n",
    "num_words_output=len(word2idx_output)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs=pad_sequences(input_sequences,maxlen=max_len_input,padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs=pad_sequences(target_input_sequences,maxlen=max_len_output,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2, 1468,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   2, 1004,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   2,  749,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   2, 1005,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " decoder_inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_targets=pad_sequences(target_sequences,maxlen=max_len_output,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1468,    1,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(r'F:\\mukulml\\NLP\\spa-eng\\glove.6B.100d.txt',encoding='utf-8') as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split() \n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare embedding matrix\n",
    "num_words=min(MAX_NUM_WORDS,len(word2idx_inputs)+1)\n",
    "embedding_matrix=np.zeros((num_words,EMBEDDING_DIM))\n",
    "for word,i in word2idx_inputs.items():\n",
    "    if i<MAX_NUM_WORDS:\n",
    "        embedding_vector=word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i]=embedding_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating embedding layer\n",
    "embedding_layer=Embedding(num_words,EMBEDDING_DIM,weights=[embedding_matrix],input_length=max_len_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating one hot targets\n",
    "decoder_one_hot_targets=np.zeros((len(input_texts),max_len_output,num_words_output),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in enumerate(decoder_targets):\n",
    "    for t,word in enumerate(d):\n",
    "        decoder_one_hot_targets[i,t,word]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    " ###building model\n",
    "#setup encoder simple\n",
    "encoder_input_placeholder=Input(shape=(max_len_input,))\n",
    "x=embedding_layer(encoder_input_placeholder)\n",
    "encoder=Bidirectional(LSTM(LATENT_DIM,return_sequences=True,dropout=0.3))\n",
    "encoder_outputs=encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs_placeholder=Input(shape=(max_len_output,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_embedding=Embedding(num_words_output,EMBEDDING_DIM)\n",
    "decoder_inputs_x=decoder_embedding(decoder_inputs_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention layer\n",
    "attn_repeat_layer=RepeatVector(max_len_input)\n",
    "attn_concat_layer=Concatenate(axis=-1)\n",
    "attn_dense1=Dense(10,activation='tanh')\n",
    "attn_dense2=Dense(1,activation=softmax_over_time)\n",
    "attn_dot=Dot(axes=1)#to perform the weighted sum of alpha(t)*h(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(h,st_1):\n",
    "    #h=h(1)......h(Tx),shape=(Tx,LATEND_DIM*2)\n",
    "    #ST_1=s(t-1),shape=(LATENT_DIM_DECODER,)\n",
    "    \n",
    "    #copy s(t-1) tx times\n",
    "    #now shape=(Tx,LATENT_DIM_DECODER)\n",
    "    st_1=attn_repeat_layer(st_1)\n",
    "    \n",
    "    #concat all h(t)'s with s(t-1)\n",
    "    #now shape (tx,LATENT_DIM_DECODER+LATENT_DIM*2)\n",
    "    x=attn_concat_layer([h,st_1])\n",
    "    \n",
    "    #neural net first layer\n",
    "    x=attn_dense1(x)\n",
    "    \n",
    "    #neural net second layer with special softmax over time\n",
    "    alphas=attn_dense2(x)\n",
    "    \n",
    "    #Dot the alphas and h's\n",
    "    #a.dot(b)=sum over a[t]*b[t]\n",
    "    \n",
    "    context = attn_dot([alphas,h])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define rest of the decoder(after attention)\n",
    "decoder_lstm=LSTM(LATENT_DIM_DECODER,return_state=True)\n",
    "decoder_dense=Dense(num_words_output,activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_s=Input(shape=(LATENT_DIM_DECODER,),name='s0')\n",
    "initial_c=Input(shape=(LATENT_DIM_DECODER,),name='c0')\n",
    "context_last_word_concat_layer=Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s and c will reassign after each step\n",
    "s=initial_s\n",
    "c=initial_c\n",
    "outputs=[]\n",
    "\n",
    "#collect output in a list at first\n",
    "for t in range(max_len_output): #ty times\n",
    "    #get the context using attention mech\n",
    "    context=one_step_attention(encoder_outputs,s)\n",
    "    \n",
    "    #we need a different layer for each time step\n",
    "    selector=Lambda(lambda x: x[:,t:t+1])\n",
    "    xt=selector(decoder_inputs_x)\n",
    "    \n",
    "    #combine\n",
    "    decoder_lstm_input=context_last_word_concat_layer([context,xt])\n",
    "    \n",
    "    #pass the combined [context,last word] into lstm\n",
    "    #along with [s,c]\n",
    "    #get the new[s,c] and output\n",
    "    o,s,c=decoder_lstm(decoder_lstm_input,initial_state=[s,c])\n",
    "    \n",
    "    #final dense layer to get next word prediction\n",
    "    decoder_outputs=decoder_dense(o)\n",
    "    outputs.append(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs' is now a list of length Ty\n",
    "# each element is of shape(batch_size,output vocab)\n",
    "#therefore we can simply  stack all outputs into 1 tensor\n",
    "#it would be of shape T X N X D\n",
    "#we would like it to be of shape N X T X D\n",
    "\n",
    "def stack_and_transpose(x):\n",
    "    # x is a lisy of length T, each element is a batch_size x output_vocab_size tensor\n",
    "    x=k.stack(x)\n",
    "    x=k.permute_dimensions(x,pattern=(1,0,2)) # is now batch_size x T x output_vocab_size\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it a layer\n",
    "stacker=Lambda(stack_and_transpose)\n",
    "outputs=stacker(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[encoder_input_placeholder,decoder_inputs_placeholder,initial_s,initial_c],outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 98s 12ms/step - loss: 2.7398 - acc: 0.6318 - val_loss: 2.6668 - val_acc: 0.6516\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "z=np.zeros((NUM_SAMPLES,LATENT_DIM_DECODER)) #initial s c\n",
    "r=model.fit([encoder_inputs,decoder_inputs,z,z],decoder_one_hot_targets,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
